{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NThanh.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNP5/s0ClgP2mPR9jpL5hme",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Huynhngocthanh/DoAn_2022/blob/main/NThanh.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 271
        },
        "id": "cd4jhasWRg3u",
        "outputId": "d6545e8f-8859-465a-ad72-a8c5b9f1b1c0"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Để hỗ trợ cả python 2 và python 3\n",
        "from __future__ import division, print_function, unicode_literals\n",
        "# list of points \n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.spatial.distance import cdist\n",
        "from matplotlib.backends.backend_pdf import PdfPages\n",
        "np.random.seed(22)\n",
        "\n",
        "means = [[2, 2], [4, 2]]\n",
        "cov = [[.7, 0], [0, .7]]\n",
        "N = 20\n",
        "X0 = np.random.multivariate_normal(means[0], cov, N) # each row is a data point \n",
        "X1 = np.random.multivariate_normal(means[1], cov, N)\n",
        "\n",
        "with PdfPages('./data.pdf') as pdf:\n",
        "    plt.plot(X0[:, 0], X0[:, 1], 'bs', markersize = 8, alpha = 1)\n",
        "    plt.plot(X1[:, 0], X1[:, 1], 'ro', markersize = 8, alpha = 1)\n",
        "    plt.axis('equal')\n",
        "    plt.ylim(0, 4)\n",
        "    plt.xlim(0, 5)\n",
        "\n",
        "    # hide tikcs \n",
        "    cur_axes = plt.gca()\n",
        "    cur_axes.axes.get_xaxis().set_ticks([])\n",
        "    cur_axes.axes.get_yaxis().set_ticks([])\n",
        "\n",
        "    plt.xlabel('$x_1$', fontsize = 20)\n",
        "    plt.ylabel('$x_2$', fontsize = 20)\n",
        "    pdf.savefig()\n",
        "    # plt.savefig('logistic_2d.png', bbox_inches='tight', dpi = 300)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5.1.1. Khai báo thư viện và tạo dữ liệu giả"
      ],
      "metadata": {
        "id": "zFl_DGI4SPzK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#tạo dữ liệu\n",
        "#danh sách các điểm\n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.spatial.distance import cdist\n",
        "np.random.seed(21)\n",
        "from matplotlib.backends.backend_pdf import PdfPages\n",
        "\n",
        "means = [[2, 2], [4, 1]]\n",
        "cov = [[.3, .2], [.2, .3]]\n",
        "N = 10\n",
        "X0 = np.random.multivariate_normal(means[0], cov, N)\n",
        "X1 = np.random.multivariate_normal(means[1], cov, N)\n",
        "X1[-1, :] = [2.7, 2]\n",
        "#X = np.concatenate((X0.T, X1.T), axis = 1)\n",
        "#y = np.concatenate((np.ones((1, N)), -1*np.ones((1, N))), axis = 1)"
      ],
      "metadata": {
        "id": "Dwuww_l4R9XX"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.vstack((X0, X1)) \n",
        "y = np.vstack((np.ones((N,1 )), -np.ones((N,1 )))).reshape((2*N,))"
      ],
      "metadata": {
        "id": "qG1kcVhaScIp"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5.1.2. Giải bài toán bằng thư viện sklearn Ta chọn C = 100 trong thí nghiệm này"
      ],
      "metadata": {
        "id": "CRoBjWKjSjGg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "C = 100 \n",
        "clf = SVC(kernel = 'linear', C = C)\n",
        "y=y.reshape(-1,1) \n",
        "clf.fit(X, y) \n",
        "\n",
        "\n",
        "w_sklearn = clf.coef_.reshape(-1, 1)\n",
        "b_sklearn = clf.intercept_[0]\n",
        "print(w_sklearn.T, b_sklearn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TU_zTToFSjwY",
        "outputId": "ebabfea7-194c-4d29-a9ce-dea8501d5a6c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-5.54202362  2.4156074 ]] 9.132415590204586\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5.1.3. Tìm nghiệm bằng giải bài toán đối ngẫu Tương tự như việc giải bài toán Hard Margin SVM, chỉ khác rằng ta có thêm ràng buộc về chặn trên của các nhân thử Lagrange"
      ],
      "metadata": {
        "id": "LHdTviMWSs2h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from cvxopt import matrix, solvers\n",
        "# build K\n",
        "V = np.concatenate((X0.T, -X1.T), axis = 1)\n",
        "K = matrix(V.T.dot(V))\n",
        "\n",
        "p = matrix(-np.ones((2*N, 1)))\n",
        "# build A, b, G, h \n",
        "G = matrix(np.vstack((-np.eye(2*N), np.eye(2*N))))\n",
        "\n",
        "h = matrix(np.vstack((np.zeros((2*N, 1)), C*np.ones((2*N, 1)))))\n",
        "A = matrix(y.reshape((-1, 2*N))) \n",
        "b = matrix(np.zeros((1, 1))) \n",
        "solvers.options['show_progress'] = False\n",
        "sol = solvers.qp(K, p, G, h, A, b)\n",
        "\n",
        "l = np.array(sol['x'])\n",
        "print('lambda = \\n', l.T)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7TAw00E6StXa",
        "outputId": "7937a263-dc93-44d0-feb2-da6a8c36d2ff"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lambda = \n",
            " [[1.26997770e-08 7.29907090e-09 6.75263620e+00 1.20067067e-08\n",
            "  8.83482181e-09 1.00135373e-08 9.49241066e-09 1.10095260e-08\n",
            "  1.09448265e-08 1.15277180e+01 3.06483278e-09 2.92217775e-09\n",
            "  3.52341246e-09 5.49363383e-09 4.48478627e-09 7.55953464e-09\n",
            "  2.73325320e-09 5.71296652e-09 5.02756847e-09 1.82803543e+01]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Trong các thành phần của lambda tìm được, có rất nhiều thành phần nhỏ tới 1e-6 hay 1e-7. Đây chính là các lambda_i = 0. Có rất nhiều phần tử xấp xỉ 9.99e+01, đây chính là các lambda_i bằng với C = 100, tương ứng với các support vectors không nằm trên margins, các sai số nhỏ xảy ra do tính toán. Các giá trị còn lại nằm giữa 0 và 100 là các giá trị tương ứng với các điểm nằm chính xác trên hai margins.\n",
        "\n",
        "Tiếp theo, ta cần tính w và b theo công thức ( 15 ) và ( 16 ) . Trước đó ta cần tìm tập hợp các điểm support và những điểm nằm trên margins"
      ],
      "metadata": {
        "id": "snlWO6NKS9JJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "S = np.where(l > 1e-5)[0] # support set \n",
        "S2 = np.where(l < .999*C)[0] \n",
        "\n",
        "M = [val for val in S if val in S2] # intersection of two lists\n",
        "\n",
        "XT = X.T # we need each column to be one data point in this alg\n",
        "VS = V[:, S]\n",
        "lS = l[S]\n",
        "yM = y[M]\n",
        "XM = XT[:, M]\n",
        "\n",
        "w_dual = VS.dot(lS).reshape(-1, 1)\n",
        "b_dual = np.mean(yM.T - w_dual.T.dot(XM))\n",
        "print(w_dual.T, b_dual)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m8WEiJfaS96K",
        "outputId": "95d96e3f-7428-408b-b502-72ccf543a1c5"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-5.54276837  2.41628387]] 9.13290685085968\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5.1.4. Tìm nghiệm bằng giải bài toán không ràng buộc Trong phương pháp này, chúng ta cần tính gradient của hàm mất mát. Như thường lệ, chúng ta cần kiểm chứng này bằng cách so sánh với numerical gradient.\n",
        "\n",
        "Chú ý rằng trong phương pháp này, ta cần dùng tham số lam = 1/C"
      ],
      "metadata": {
        "id": "ahZpyxV5TD_x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X0_bar = np.vstack((X0.T, np.ones((1, N)))) # extended data\n",
        "X1_bar = np.vstack((X1.T, np.ones((1, N)))) # extended data \n",
        "\n",
        "Z = np.hstack((X0_bar, - X1_bar)) # as in (22)\n",
        "lam = 1./C\n",
        "\n",
        "def cost(w):\n",
        "    u = w.T.dot(Z) # as in (23)\n",
        "    return (np.sum(np.maximum(0, 1 - u)) + \\\n",
        "        .5*lam*np.sum(w*w)) - .5*lam*w[-1]*w[-1] # no bias \n",
        "\n",
        "def grad(w):\n",
        "    u = w.T.dot(Z) # as in (23)\n",
        "    H = np.where(u < 1)[1]\n",
        "    ZS = Z[:, H]\n",
        "    g = (-np.sum(ZS, axis = 1, keepdims = True) + lam*w)\n",
        "    g[-1] -= lam*w[-1] # no weight decay on bias\n",
        "    return g\n",
        "    \n",
        "eps = 1e-6\n",
        "def num_grad(w):\n",
        "    g = np.zeros_like(w)\n",
        "    for i in range(len(w)):\n",
        "        wp = w.copy()\n",
        "        wm = w.copy()\n",
        "        wp[i] += eps \n",
        "        wm[i] -= eps \n",
        "        g[i] = (cost(wp) - cost(wm))/(2*eps)\n",
        "    return g \n",
        "\n",
        "w0 = np.random.randn(X0_bar.shape[0], 1) \n",
        "g1 = grad(w0)\n",
        "g2 = num_grad(w0)\n",
        "diff = np.linalg.norm(g1 - g2)\n",
        "print('Gradient different: %f' %diff)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SzoOxHzRTEXj",
        "outputId": "fc56eac7-951e-4cbe-bd90-413bb0d8f2c6"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradient different: 0.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vì sự khác nhau giữa hai cách tính gradient là bằng 0, ta có thể yên tâm rằng gradient tính được là chính xác.\n",
        "\n",
        "Sau khi chắc chắn rằng gradient tìm được đã chính xác, ta có thể bắt đầu làm Gradient Descent"
      ],
      "metadata": {
        "id": "WXdg2rq9TRM5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def grad_descent(w0, eta):\n",
        "    w = w0\n",
        "    it = 0 \n",
        "    while it < 100000:\n",
        "        it = it + 1\n",
        "        g = grad(w)\n",
        "        w -= eta*g\n",
        "        if (it % 10000) == 1:\n",
        "            print('iter %d' %it + ' cost: %f' %cost(w))\n",
        "        if np.linalg.norm(g) < 1e-5:\n",
        "            break \n",
        "    return w \n",
        "w0 = np.random.randn(X0_bar.shape[0], 1) \n",
        "w = grad_descent(w0, 0.001)\n",
        "w_hinge = w[:-1].reshape(-1, 1)\n",
        "b_hinge = w[-1]\n",
        "print(w_hinge.T, b_hinge)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1mmSm1smTRoF",
        "outputId": "63147247-bc5a-41f6-ae1d-8c88e35fd0d4"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iter 1 cost: 47.818294\n",
            "iter 10001 cost: 1.306777\n",
            "iter 20001 cost: 0.979035\n",
            "iter 30001 cost: 0.670496\n",
            "iter 40001 cost: 0.389639\n",
            "iter 50001 cost: 0.183199\n",
            "iter 60001 cost: 0.183199\n",
            "iter 70001 cost: 0.183198\n",
            "iter 80001 cost: 0.183198\n",
            "iter 90001 cost: 0.183197\n",
            "[[-5.54894385  2.41853936]] [9.14489666]\n"
          ]
        }
      ]
    }
  ]
}